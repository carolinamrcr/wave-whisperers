{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43af540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import TimeSeriesSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4e01682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and site names setup\n",
    "waves_folder_path = \"./dataset_Ondas\"\n",
    "shorelines_folder_path = \"./dataset_linhascosta\"\n",
    "transects_folder_path = \"./dataset_transects\"\n",
    "site_names = ['CVCC','CCFT','FTAD','ADLA','LABI',\n",
    "              'TRAT','ATMC','MCCO','CCCL','NNOR',\n",
    "              'MEIA','TORR','CVMR','MRMG','MGVR',\n",
    "              'COSN','VAGR','GBHA','BARR','MIRA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3915b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store DataFrames\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a04414e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each file name\n",
    "for name in site_names:\n",
    "    # Construct the file paths\n",
    "    waves_file_path = os.path.join(waves_folder_path, f\"{name}_wave_timeseries.csv\")\n",
    "    shorelines_file_path = os.path.join(shorelines_folder_path, f\"{name}_shoreline_timeseries.csv\")\n",
    "    transects_file_path = os.path.join(transects_folder_path, f\"{name}_T.geojson\")\n",
    "\n",
    "    # Read the waves CSV files into DataFrame\n",
    "    waves_df = pd.read_csv(waves_file_path, sep=',', header=0) # Set header=0 to use the first row as column headers\n",
    "    \n",
    "    waves_df['time'] = pd.to_datetime(waves_df['time'])\n",
    "    waves_df.set_index('time', inplace=True)\n",
    "    waves_df['years'] = waves_df.index.year\n",
    "    waves_df['months'] = waves_df.index.month\n",
    "    waves_df.index = pd.MultiIndex.from_tuples(\n",
    "    [(year, month) for year, month in zip(waves_df.index.year, waves_df.index.month)],\n",
    "    names=['years', 'months'])\n",
    "    waves_df = waves_df[waves_df['years'] != 1983] # Remove 1983 because satellite data is not available for that year\n",
    "    \n",
    "    \n",
    "    # List of directions (16 directions compass rose)\n",
    "    directions = ['N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE', 'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW', 'NNW']\n",
    "    def degrees_to_direction(wave_direction_degrees):\n",
    "        if wave_direction_degrees >= 0 and   wave_direction_degrees <= 11.25:\n",
    "            return 'N'\n",
    "        elif wave_direction_degrees <= 33.75:\n",
    "            return 'NNE'\n",
    "        elif wave_direction_degrees <= 56.25:\n",
    "            return 'NE'\n",
    "        elif wave_direction_degrees <= 78.75:\n",
    "            return 'ENE'\n",
    "        elif wave_direction_degrees <= 101.25:\n",
    "            return 'E'\n",
    "        elif wave_direction_degrees <= 123.75:\n",
    "            return 'ESE'\n",
    "        elif wave_direction_degrees <= 146.25:\n",
    "            return 'SE'\n",
    "        elif wave_direction_degrees <= 168.75:\n",
    "            return 'SSE'\n",
    "        elif wave_direction_degrees <= 191.25:\n",
    "            return 'S'\n",
    "        elif wave_direction_degrees <= 213.75:\n",
    "            return 'SSW'\n",
    "        elif wave_direction_degrees <= 236.25:\n",
    "            return 'SW'\n",
    "        elif wave_direction_degrees <= 258.75:\n",
    "            return 'WSW'\n",
    "        elif wave_direction_degrees <= 281.25:\n",
    "            return 'W'\n",
    "        elif wave_direction_degrees <= 303.75:\n",
    "            return 'WNW'\n",
    "        elif wave_direction_degrees <= 326.25:\n",
    "            return 'NW'\n",
    "        elif wave_direction_degrees <= 348.75:\n",
    "            return 'NNW'\n",
    "        elif wave_direction_degrees <= 360:\n",
    "            return 'N'\n",
    "        else:\n",
    "            return 'false'\n",
    "\n",
    "    # One-hot encode the 'mwd' column\n",
    "    waves_df['mwd'] = waves_df['mwd'].apply(degrees_to_direction)\n",
    "\n",
    "    # Create a DataFrame of dummy variables for 'mwd'\n",
    "    one_hot_encode = pd.get_dummies(waves_df['mwd'], prefix='from')\n",
    "\n",
    "    # Concatenate the one-hot encoded columns to the original DataFrame\n",
    "    waves_df = pd.concat([waves_df, one_hot_encode], axis=1)\n",
    "    waves_df = waves_df.drop('mwd', axis=1)\n",
    "\n",
    "    # Iterate through directions and create new columns for each direction's pp1d and swh\n",
    "    for direction in directions:\n",
    "        # Create new columns for pp1d and swh\n",
    "        pp1d_column_name = f'{name}_pp1d_from_{direction}'\n",
    "        swh_column_name = f'{name}_swh_from_{direction}'\n",
    "    \n",
    "        # Use boolean indexing to set values based on the condition\n",
    "        waves_df[pp1d_column_name] = waves_df['pp1d'] * waves_df[f'from_{direction}']\n",
    "        waves_df[swh_column_name] = waves_df['swh'] * waves_df[f'from_{direction}']\n",
    "    \n",
    "    # Drop the original 'mwd' column and the 'pp1d' and 'swh' columns\n",
    "    waves_df.drop(columns=[f'from_{direction}' for direction in directions], inplace=True)\n",
    "    waves_df.drop(columns=['pp1d','swh'], inplace=True)\n",
    "\n",
    "    # Read the shorelines CSV files into DataFrame\n",
    "    shorelines_df = pd.read_csv(shorelines_file_path)\n",
    "    shorelines_df = shorelines_df.iloc[:, 1:]\n",
    "    shorelines_df['dates'] = pd.to_datetime(shorelines_df['dates'])\n",
    "    shorelines_df.set_index('dates', inplace=True)\n",
    "    shorelines_df['years'] = shorelines_df.index.year\n",
    "    shorelines_df['months'] = shorelines_df.index.month\n",
    "    shorelines_df.index = pd.MultiIndex.from_tuples(\n",
    "    [(year, month) for year, month in zip(shorelines_df.index.year, shorelines_df.index.month)],\n",
    "    names=['years', 'months'])\n",
    "\n",
    "   \n",
    "    # Read the transects GeoJSON file into a GeoDataFrame\n",
    "    transects_gdf = gpd.read_file(transects_file_path, driver='GeoJSON')\n",
    "\n",
    "    # Add DataFrames to the dictionary with site name as key\n",
    "    data[name] = {\n",
    "        'waves': waves_df,\n",
    "        'shorelines': shorelines_df,\n",
    "        'transects': transects_gdf\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "282e6b31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CCFT_1</th>\n",
       "      <th>CCFT_2</th>\n",
       "      <th>CCFT_3</th>\n",
       "      <th>CCFT_4</th>\n",
       "      <th>CCFT_5</th>\n",
       "      <th>CCFT_6</th>\n",
       "      <th>CCFT_7</th>\n",
       "      <th>CCFT_8</th>\n",
       "      <th>CCFT_9</th>\n",
       "      <th>CCFT_10</th>\n",
       "      <th>years</th>\n",
       "      <th>months</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <th>months</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1984</th>\n",
       "      <th>4</th>\n",
       "      <td>131.717585</td>\n",
       "      <td>157.047471</td>\n",
       "      <td>100.058992</td>\n",
       "      <td>65.354326</td>\n",
       "      <td>56.503256</td>\n",
       "      <td>26.773429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>117.167081</td>\n",
       "      <td>78.879555</td>\n",
       "      <td>1984</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>129.465202</td>\n",
       "      <td>154.734336</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1984</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>119.668047</td>\n",
       "      <td>140.186758</td>\n",
       "      <td>81.285109</td>\n",
       "      <td>48.430575</td>\n",
       "      <td>36.155372</td>\n",
       "      <td>24.228479</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>113.328121</td>\n",
       "      <td>67.895648</td>\n",
       "      <td>1984</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>115.009565</td>\n",
       "      <td>140.487681</td>\n",
       "      <td>84.992270</td>\n",
       "      <td>49.368228</td>\n",
       "      <td>35.643790</td>\n",
       "      <td>30.910373</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119.407154</td>\n",
       "      <td>77.699004</td>\n",
       "      <td>1984</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>111.353530</td>\n",
       "      <td>141.966511</td>\n",
       "      <td>87.893720</td>\n",
       "      <td>49.643060</td>\n",
       "      <td>37.612934</td>\n",
       "      <td>30.549023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>118.115768</td>\n",
       "      <td>64.493328</td>\n",
       "      <td>1984</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2022</th>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>157.442800</td>\n",
       "      <td>87.408285</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.619913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>94.378403</td>\n",
       "      <td>59.565591</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>47.411269</td>\n",
       "      <td>105.570633</td>\n",
       "      <td>67.595964</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>136.089446</td>\n",
       "      <td>148.179310</td>\n",
       "      <td>57.405931</td>\n",
       "      <td>31.692820</td>\n",
       "      <td>6.991199</td>\n",
       "      <td>-12.821248</td>\n",
       "      <td>-22.457253</td>\n",
       "      <td>27.869996</td>\n",
       "      <td>88.559314</td>\n",
       "      <td>52.358776</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>139.734505</td>\n",
       "      <td>152.850217</td>\n",
       "      <td>84.838118</td>\n",
       "      <td>34.742395</td>\n",
       "      <td>11.491148</td>\n",
       "      <td>-7.419695</td>\n",
       "      <td>-2.770608</td>\n",
       "      <td>31.340796</td>\n",
       "      <td>86.182920</td>\n",
       "      <td>53.393450</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>862 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CCFT_1      CCFT_2      CCFT_3     CCFT_4     CCFT_5  \\\n",
       "years months                                                             \n",
       "1984  4       131.717585  157.047471  100.058992  65.354326  56.503256   \n",
       "      5       129.465202  154.734336         NaN        NaN        NaN   \n",
       "      7       119.668047  140.186758   81.285109  48.430575  36.155372   \n",
       "      7       115.009565  140.487681   84.992270  49.368228  35.643790   \n",
       "      8       111.353530  141.966511   87.893720  49.643060  37.612934   \n",
       "...                  ...         ...         ...        ...        ...   \n",
       "2022  11             NaN  157.442800   87.408285        NaN        NaN   \n",
       "      11             NaN         NaN         NaN        NaN        NaN   \n",
       "      12      136.089446  148.179310   57.405931  31.692820   6.991199   \n",
       "      12      139.734505  152.850217   84.838118  34.742395  11.491148   \n",
       "      12             NaN         NaN         NaN        NaN        NaN   \n",
       "\n",
       "                 CCFT_6     CCFT_7     CCFT_8      CCFT_9    CCFT_10  years  \\\n",
       "years months                                                                  \n",
       "1984  4       26.773429        NaN        NaN  117.167081  78.879555   1984   \n",
       "      5             NaN        NaN        NaN         NaN        NaN   1984   \n",
       "      7       24.228479        NaN        NaN  113.328121  67.895648   1984   \n",
       "      7       30.910373        NaN        NaN  119.407154  77.699004   1984   \n",
       "      8       30.549023        NaN        NaN  118.115768  64.493328   1984   \n",
       "...                 ...        ...        ...         ...        ...    ...   \n",
       "2022  11            NaN   5.619913        NaN   94.378403  59.565591   2022   \n",
       "      11            NaN        NaN  47.411269  105.570633  67.595964   2022   \n",
       "      12     -12.821248 -22.457253  27.869996   88.559314  52.358776   2022   \n",
       "      12      -7.419695  -2.770608  31.340796   86.182920  53.393450   2022   \n",
       "      12            NaN        NaN        NaN         NaN        NaN   2022   \n",
       "\n",
       "              months  \n",
       "years months          \n",
       "1984  4            4  \n",
       "      5            5  \n",
       "      7            7  \n",
       "      7            7  \n",
       "      8            8  \n",
       "...              ...  \n",
       "2022  11          11  \n",
       "      11          11  \n",
       "      12          12  \n",
       "      12          12  \n",
       "      12          12  \n",
       "\n",
       "[862 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['CCFT']['shorelines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8bba3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the results\n",
    "annual_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "128270fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over keys in the data dictionary\n",
    "for name in data.keys():\n",
    "    \n",
    "    shoreline_df = data[name]['shorelines']\n",
    "\n",
    "    # Create a MultiIndex with all possible combinations of years and months\n",
    "    all_years = range(1984, 2023)\n",
    "    all_months = range(1, 13)\n",
    "    all_combinations = [(year, month) for year in all_years for month in all_months]\n",
    "\n",
    "    full_index = pd.MultiIndex.from_tuples(all_combinations, names=['years', 'months'])\n",
    "\n",
    "    # Group by the MultiIndex and calculate the median\n",
    "    shoreline_df_annual = shoreline_df.groupby(level=['years', 'months']).median(numeric_only=True)\n",
    "\n",
    "    # Reindex with the full MultiIndex to fill missing combinations with NaN\n",
    "    shoreline_df_annual = shoreline_df_annual.reindex(full_index)\n",
    "    \n",
    "    # Check for columns that only have NaN values after reindexing\n",
    "    empty_columns_after_reindexing = shoreline_df_annual.columns[shoreline_df_annual.isnull().all()]\n",
    "\n",
    "   # Drop year and month columns\n",
    "    shoreline_df_annual = shoreline_df_annual.drop(['years', 'months'], axis=1)\n",
    "\n",
    "        # Iterate over each column in the DataFrame \n",
    "\n",
    "    # Iterate over each column in the DataFrame\n",
    "    for i in range(1, len(shoreline_df_annual.columns) - 1):\n",
    "        col = shoreline_df_annual.columns[i]\n",
    "\n",
    "        # Skip columns with names \"years\" or \"months\"\n",
    "        if col.lower() not in ['years', 'months']:\n",
    "            for idx in shoreline_df_annual[col][shoreline_df_annual[col].isnull()].index:\n",
    "                prev_col = shoreline_df_annual.columns[i - 1] if i - 1 >= 0 else None\n",
    "                next_col = shoreline_df_annual.columns[i + 1] if i + 1 < len(shoreline_df_annual.columns) else None\n",
    "\n",
    "                # Check if adjacent columns have non-NaN values and use them for filling NaNs\n",
    "                if prev_col and next_col:\n",
    "                    prev_val = shoreline_df_annual.at[idx, prev_col]\n",
    "                    next_val = shoreline_df_annual.at[idx, next_col]\n",
    "                    if pd.notnull(prev_val) and pd.notnull(next_val):\n",
    "                        shoreline_df_annual.at[idx, col] = (prev_val + next_val) / 2\n",
    "                    elif pd.notnull(prev_val):\n",
    "                        shoreline_df_annual.at[idx, col] = prev_val\n",
    "                    elif pd.notnull(next_val):\n",
    "                        shoreline_df_annual.at[idx, col] = next_val\n",
    "                elif prev_col:\n",
    "                    prev_val = shoreline_df_annual.at[idx, prev_col]\n",
    "                    if pd.notnull(prev_val):\n",
    "                        shoreline_df_annual.at[idx, col] = prev_val\n",
    "                elif next_col:\n",
    "                    next_val = shoreline_df_annual.at[idx, next_col]\n",
    "                    if pd.notnull(next_val):\n",
    "                        shoreline_df_annual.at[idx, col] = next_val\n",
    "\n",
    "    # Perform median replacement only for columns that are not \"years\" or \"months\"\n",
    "    for column in shoreline_df_annual.columns:\n",
    "        if column.lower() not in ['years', 'months']:\n",
    "            # Check if there are any NaN values in the column\n",
    "            if shoreline_df_annual[column].isnull().any():\n",
    "                # Calculate the median value of the column (excluding NaN values)\n",
    "                median_value = shoreline_df_annual[column].median()\n",
    "        \n",
    "                # Replace NaN values with the calculated median value\n",
    "                shoreline_df_annual[column].fillna(median_value, inplace=True)\n",
    "\n",
    "    # Ensure no NaNs are left before model training\n",
    "    if shoreline_df_annual.isna().any().any():\n",
    "        print(f\"NaNs remain in shorelines data for {name}\")\n",
    "        continue  # Skip this iteration if NaNs are still present\n",
    "\n",
    "\n",
    "    # Add the DataFrame to the dictionary with site name as key\n",
    "    annual_data[name] = {\n",
    "        'shorelines': shoreline_df_annual\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3db467d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>CCFT_1</th>\n",
       "      <th>CCFT_2</th>\n",
       "      <th>CCFT_3</th>\n",
       "      <th>CCFT_4</th>\n",
       "      <th>CCFT_5</th>\n",
       "      <th>CCFT_6</th>\n",
       "      <th>CCFT_7</th>\n",
       "      <th>CCFT_8</th>\n",
       "      <th>CCFT_9</th>\n",
       "      <th>CCFT_10</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>years</th>\n",
       "      <th>months</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1984</th>\n",
       "      <th>1</th>\n",
       "      <td>126.276176</td>\n",
       "      <td>146.092807</td>\n",
       "      <td>87.699840</td>\n",
       "      <td>42.732468</td>\n",
       "      <td>19.573753</td>\n",
       "      <td>10.433007</td>\n",
       "      <td>12.988661</td>\n",
       "      <td>44.899836</td>\n",
       "      <td>102.411942</td>\n",
       "      <td>69.297154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>126.276176</td>\n",
       "      <td>146.092807</td>\n",
       "      <td>87.699840</td>\n",
       "      <td>42.732468</td>\n",
       "      <td>19.573753</td>\n",
       "      <td>10.433007</td>\n",
       "      <td>12.988661</td>\n",
       "      <td>44.899836</td>\n",
       "      <td>102.411942</td>\n",
       "      <td>69.297154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126.276176</td>\n",
       "      <td>146.092807</td>\n",
       "      <td>87.699840</td>\n",
       "      <td>42.732468</td>\n",
       "      <td>19.573753</td>\n",
       "      <td>10.433007</td>\n",
       "      <td>12.988661</td>\n",
       "      <td>44.899836</td>\n",
       "      <td>102.411942</td>\n",
       "      <td>69.297154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>131.717585</td>\n",
       "      <td>157.047471</td>\n",
       "      <td>100.058992</td>\n",
       "      <td>65.354326</td>\n",
       "      <td>56.503256</td>\n",
       "      <td>26.773429</td>\n",
       "      <td>26.773429</td>\n",
       "      <td>71.970255</td>\n",
       "      <td>117.167081</td>\n",
       "      <td>78.879555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>129.465202</td>\n",
       "      <td>154.734336</td>\n",
       "      <td>154.734336</td>\n",
       "      <td>154.734336</td>\n",
       "      <td>154.734336</td>\n",
       "      <td>154.734336</td>\n",
       "      <td>154.734336</td>\n",
       "      <td>154.734336</td>\n",
       "      <td>154.734336</td>\n",
       "      <td>69.297154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2022</th>\n",
       "      <th>8</th>\n",
       "      <td>168.441310</td>\n",
       "      <td>185.994583</td>\n",
       "      <td>112.212179</td>\n",
       "      <td>82.721207</td>\n",
       "      <td>36.299678</td>\n",
       "      <td>13.617888</td>\n",
       "      <td>17.349859</td>\n",
       "      <td>65.297274</td>\n",
       "      <td>113.244690</td>\n",
       "      <td>82.535752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>163.526648</td>\n",
       "      <td>172.052519</td>\n",
       "      <td>102.733551</td>\n",
       "      <td>81.812022</td>\n",
       "      <td>51.676672</td>\n",
       "      <td>30.309495</td>\n",
       "      <td>12.384210</td>\n",
       "      <td>44.899836</td>\n",
       "      <td>112.504532</td>\n",
       "      <td>86.859968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>155.641212</td>\n",
       "      <td>181.973479</td>\n",
       "      <td>116.273569</td>\n",
       "      <td>88.437798</td>\n",
       "      <td>42.148920</td>\n",
       "      <td>13.691258</td>\n",
       "      <td>10.669287</td>\n",
       "      <td>42.372890</td>\n",
       "      <td>116.831469</td>\n",
       "      <td>75.864496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>143.606714</td>\n",
       "      <td>157.366743</td>\n",
       "      <td>85.605895</td>\n",
       "      <td>38.036442</td>\n",
       "      <td>14.352221</td>\n",
       "      <td>-6.690595</td>\n",
       "      <td>-3.293454</td>\n",
       "      <td>27.724979</td>\n",
       "      <td>92.185263</td>\n",
       "      <td>58.708060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>137.911975</td>\n",
       "      <td>150.514764</td>\n",
       "      <td>71.122025</td>\n",
       "      <td>33.217607</td>\n",
       "      <td>9.241174</td>\n",
       "      <td>-10.120472</td>\n",
       "      <td>-12.613930</td>\n",
       "      <td>29.605396</td>\n",
       "      <td>87.371117</td>\n",
       "      <td>52.876113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  CCFT_1      CCFT_2      CCFT_3      CCFT_4      CCFT_5  \\\n",
       "years months                                                               \n",
       "1984  1       126.276176  146.092807   87.699840   42.732468   19.573753   \n",
       "      2       126.276176  146.092807   87.699840   42.732468   19.573753   \n",
       "      3       126.276176  146.092807   87.699840   42.732468   19.573753   \n",
       "      4       131.717585  157.047471  100.058992   65.354326   56.503256   \n",
       "      5       129.465202  154.734336  154.734336  154.734336  154.734336   \n",
       "...                  ...         ...         ...         ...         ...   \n",
       "2022  8       168.441310  185.994583  112.212179   82.721207   36.299678   \n",
       "      9       163.526648  172.052519  102.733551   81.812022   51.676672   \n",
       "      10      155.641212  181.973479  116.273569   88.437798   42.148920   \n",
       "      11      143.606714  157.366743   85.605895   38.036442   14.352221   \n",
       "      12      137.911975  150.514764   71.122025   33.217607    9.241174   \n",
       "\n",
       "                  CCFT_6      CCFT_7      CCFT_8      CCFT_9    CCFT_10  \n",
       "years months                                                             \n",
       "1984  1        10.433007   12.988661   44.899836  102.411942  69.297154  \n",
       "      2        10.433007   12.988661   44.899836  102.411942  69.297154  \n",
       "      3        10.433007   12.988661   44.899836  102.411942  69.297154  \n",
       "      4        26.773429   26.773429   71.970255  117.167081  78.879555  \n",
       "      5       154.734336  154.734336  154.734336  154.734336  69.297154  \n",
       "...                  ...         ...         ...         ...        ...  \n",
       "2022  8        13.617888   17.349859   65.297274  113.244690  82.535752  \n",
       "      9        30.309495   12.384210   44.899836  112.504532  86.859968  \n",
       "      10       13.691258   10.669287   42.372890  116.831469  75.864496  \n",
       "      11       -6.690595   -3.293454   27.724979   92.185263  58.708060  \n",
       "      12      -10.120472  -12.613930   29.605396   87.371117  52.876113  \n",
       "\n",
       "[468 rows x 10 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annual_data['CCFT']['shorelines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a560a80b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ed8210",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Iterate over keys in the data dictionary\n",
    "for name in data.keys():\n",
    "    waves_df = data[name]['waves']\n",
    "\n",
    "    waves_df = waves_df.drop(['years', 'months'], axis=1)\n",
    "    \n",
    "    waves_df_annual = waves_df.groupby([waves_df.index.get_level_values('years'), waves_df.index.get_level_values('months')]).agg(\n",
    "           {\n",
    "        f'{name}_pp1d_from_N'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_N'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_NNE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_NNE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_NE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_NE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_ENE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_ENE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_E'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_E'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_ESE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_ESE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_SE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_SE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_SSE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_SSE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_S'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_S'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_SSW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_SSW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_SW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_SW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_WSW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_WSW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_W'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_W'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_WNW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_WNW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_NW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_NW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_NNW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_NNW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None\n",
    "        })\n",
    "\n",
    "    #waves_df_annual = waves_df_annual.fillna(0)\n",
    "    \n",
    "    shoreline_df = data[name]['shorelines']\n",
    "\n",
    "    # Create a MultiIndex with all possible combinations of years and months\n",
    "    all_years = range(1984, 2023)\n",
    "    all_months = range(1, 13)\n",
    "    all_combinations = [(year, month) for year in all_years for month in all_months]\n",
    "\n",
    "    full_index = pd.MultiIndex.from_tuples(all_combinations, names=['years', 'months'])\n",
    "\n",
    "    # Group by the MultiIndex and calculate the median\n",
    "    shoreline_df_annual = shoreline_df.groupby(level=['years', 'months']).median(numeric_only=True)\n",
    "\n",
    "    # Reindex with the full MultiIndex to fill missing combinations with NaN\n",
    "    shoreline_df_annual = shoreline_df_annual.reindex(full_index)\n",
    "    \n",
    "    # Check for columns that only have NaN values after reindexing\n",
    "    empty_columns_after_reindexing = shoreline_df_annual.columns[shoreline_df_annual.isnull().all()]\n",
    "\n",
    "    # Output the results\n",
    "    print(f\"Columns with only NaN values after reindexing in '{name}' dataset: {empty_columns_after_reindexing.tolist()}\")\n",
    "    \n",
    "    # Drop year and month columns\n",
    "    shoreline_df_annual = shoreline_df_annual.drop(['years', 'months'], axis=1)\n",
    "\n",
    "        # Iterate over each column in the DataFrame \n",
    "\n",
    "    for i in range(1, len(shoreline_df_annual.columns) - 1):\n",
    "        col = shoreline_df_annual.columns[i]\n",
    "    \n",
    "        # Skip columns with names \"years\" or \"months\"\n",
    "        if col.lower() not in ['years', 'months']:\n",
    "            prev_col = shoreline_df_annual.columns[i - 1] if i - 1 >= 0 else None\n",
    "            next_col = shoreline_df_annual.columns[i + 1] if i + 1 < len(shoreline_df_annual.columns) else None\n",
    "\n",
    "            # Check if there are any NaN values in the current column\n",
    "            if shoreline_df_annual[col].isnull().any():\n",
    "                # Fill NaN values with the mean of the available previous and next columns\n",
    "                if prev_col is not None and next_col is not None:\n",
    "                    shoreline_df_annual[col] = (shoreline_df_annual[prev_col] + shoreline_df_annual[next_col]) / 2\n",
    "                elif prev_col is not None:\n",
    "                    shoreline_df_annual[col] = shoreline_df_annual[prev_col]\n",
    "                elif next_col is not None:\n",
    "                    shoreline_df_annual[col] = shoreline_df_annual[next_col]\n",
    "                else:\n",
    "                    # If there are no immediate previous and next columns, extend the search to 3 columns\n",
    "                    prev_cols = [shoreline_df_annual.columns[j] for j in range(i - 2, i) if j >= 0]\n",
    "                    next_cols = [shoreline_df_annual.columns[j] for j in range(i + 1, i + 4) if j < len(shoreline_df_annual.columns)]\n",
    "\n",
    "                    available_cols = prev_cols + next_cols\n",
    "\n",
    "                    # Filter out None values (columns that are out of range)\n",
    "                    available_cols = [col for col in available_cols if col is not None]\n",
    "\n",
    "                    # Take the mean of available columns\n",
    "                    if len(available_cols) > 0:\n",
    "                        shoreline_df_annual[col] = shoreline_df_annual[available_cols].mean(axis=1)\n",
    "\n",
    "    # Perform median replacement only for columns that are not \"years\" or \"months\"\n",
    "    for column in shoreline_df_annual.columns:\n",
    "        if column.lower() not in ['years', 'months']:\n",
    "            # Check if there are any NaN values in the column\n",
    "            if shoreline_df_annual[column].isnull().any():\n",
    "                # Calculate the median value of the column (excluding NaN values)\n",
    "                median_value = shoreline_df_annual[column].median()\n",
    "        \n",
    "                # Replace NaN values with the calculated median value\n",
    "                shoreline_df_annual[column].fillna(median_value, inplace=True)\n",
    "    \n",
    "    \n",
    "    if shoreline_df_annual.isna().any().any():\n",
    "        print(\"There are still NaN values in the DataFrame\")\n",
    "    else:\n",
    "        print(\"All NaN values have been filled\")\n",
    "    \n",
    "     \n",
    "                \n",
    "    # Add the DataFrame to the dictionary with site name as key\n",
    "    annual_data[name] = {\n",
    "        'waves': waves_df_annual,\n",
    "        'shorelines': shoreline_df_annual\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5dcaab",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_data['CCFT']['shorelines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5bd6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the 'shorelines' DataFrame for 'TRAT'\n",
    "shorelines_df = annual_data['TRAT']['shorelines']\n",
    "\n",
    "# Check for columns that only have NaN values\n",
    "empty_columns = shorelines_df.columns[shorelines_df.isnull().all()]\n",
    "\n",
    "# Output the results\n",
    "print(f\"Columns with only NaN values in 'TRAT' shorelines dataset: {empty_columns.tolist()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
