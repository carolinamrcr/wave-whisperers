{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f8f4507",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fff35683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths and site names setup\n",
    "waves_folder_path = \"./dataset_Ondas\"\n",
    "shorelines_folder_path = \"./dataset_linhascosta\"\n",
    "transects_folder_path = \"./dataset_transects\"\n",
    "site_names = ['CVCC','CCFT','FTAD','ADLA','LABI',\n",
    "              'TRAT','ATMC','MCCO','CCCL','NNOR',\n",
    "              'MEIA','TORR','CVMR','MRMG','MGVR',\n",
    "              'COSN','VAGR','GBHA','BARR','MIRA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "512db0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty dictionary to store DataFrames\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4d70d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each file name\n",
    "for name in site_names:\n",
    "    # Construct the file paths\n",
    "    waves_file_path = os.path.join(waves_folder_path, f\"{name}_wave_timeseries.csv\")\n",
    "    shorelines_file_path = os.path.join(shorelines_folder_path, f\"{name}_shoreline_timeseries.csv\")\n",
    "    transects_file_path = os.path.join(transects_folder_path, f\"{name}_T.geojson\")\n",
    "\n",
    "    # Read the waves CSV files into DataFrame\n",
    "    waves_df = pd.read_csv(waves_file_path, sep=',', header=0) # Set header=0 to use the first row as column headers\n",
    "    \n",
    "    waves_df['time'] = pd.to_datetime(waves_df['time'])\n",
    "    waves_df.set_index('time', inplace=True)\n",
    "    waves_df['years'] = waves_df.index.year\n",
    "    waves_df['months'] = waves_df.index.month\n",
    "    waves_df.index = pd.MultiIndex.from_tuples(\n",
    "    [(year, month) for year, month in zip(waves_df.index.year, waves_df.index.month)],\n",
    "    names=['years', 'months'])\n",
    "    waves_df = waves_df[waves_df['years'] != 1983] # Remove 1983 because satellite data is not available for that year\n",
    "    \n",
    "    \n",
    "    # List of directions (16 directions compass rose)\n",
    "    directions = ['N', 'NNE', 'NE', 'ENE', 'E', 'ESE', 'SE', 'SSE', 'S', 'SSW', 'SW', 'WSW', 'W', 'WNW', 'NW', 'NNW']\n",
    "    def degrees_to_direction(wave_direction_degrees):\n",
    "        if wave_direction_degrees >= 0 and   wave_direction_degrees <= 11.25:\n",
    "            return 'N'\n",
    "        elif wave_direction_degrees <= 33.75:\n",
    "            return 'NNE'\n",
    "        elif wave_direction_degrees <= 56.25:\n",
    "            return 'NE'\n",
    "        elif wave_direction_degrees <= 78.75:\n",
    "            return 'ENE'\n",
    "        elif wave_direction_degrees <= 101.25:\n",
    "            return 'E'\n",
    "        elif wave_direction_degrees <= 123.75:\n",
    "            return 'ESE'\n",
    "        elif wave_direction_degrees <= 146.25:\n",
    "            return 'SE'\n",
    "        elif wave_direction_degrees <= 168.75:\n",
    "            return 'SSE'\n",
    "        elif wave_direction_degrees <= 191.25:\n",
    "            return 'S'\n",
    "        elif wave_direction_degrees <= 213.75:\n",
    "            return 'SSW'\n",
    "        elif wave_direction_degrees <= 236.25:\n",
    "            return 'SW'\n",
    "        elif wave_direction_degrees <= 258.75:\n",
    "            return 'WSW'\n",
    "        elif wave_direction_degrees <= 281.25:\n",
    "            return 'W'\n",
    "        elif wave_direction_degrees <= 303.75:\n",
    "            return 'WNW'\n",
    "        elif wave_direction_degrees <= 326.25:\n",
    "            return 'NW'\n",
    "        elif wave_direction_degrees <= 348.75:\n",
    "            return 'NNW'\n",
    "        elif wave_direction_degrees <= 360:\n",
    "            return 'N'\n",
    "        else:\n",
    "            return 'false'\n",
    "\n",
    "    # One-hot encode the 'mwd' column\n",
    "    waves_df['mwd'] = waves_df['mwd'].apply(degrees_to_direction)\n",
    "\n",
    "    # Create a DataFrame of dummy variables for 'mwd'\n",
    "    one_hot_encode = pd.get_dummies(waves_df['mwd'], prefix='from')\n",
    "\n",
    "    # Concatenate the one-hot encoded columns to the original DataFrame\n",
    "    waves_df = pd.concat([waves_df, one_hot_encode], axis=1)\n",
    "    waves_df = waves_df.drop('mwd', axis=1)\n",
    "\n",
    "    # Iterate through directions and create new columns for each direction's pp1d and swh\n",
    "    for direction in directions:\n",
    "        # Create new columns for pp1d and swh\n",
    "        pp1d_column_name = f'{name}_pp1d_from_{direction}'\n",
    "        swh_column_name = f'{name}_swh_from_{direction}'\n",
    "    \n",
    "        # Use boolean indexing to set values based on the condition\n",
    "        waves_df[pp1d_column_name] = waves_df['pp1d'] * waves_df[f'from_{direction}']\n",
    "        waves_df[swh_column_name] = waves_df['swh'] * waves_df[f'from_{direction}']\n",
    "    \n",
    "    # Drop the original 'mwd' column and the 'pp1d' and 'swh' columns\n",
    "    waves_df.drop(columns=[f'from_{direction}' for direction in directions], inplace=True)\n",
    "    waves_df.drop(columns=['pp1d','swh'], inplace=True)\n",
    "\n",
    "    # Read the shorelines CSV files into DataFrame\n",
    "    shorelines_df = pd.read_csv(shorelines_file_path)\n",
    "    shorelines_df = shorelines_df.iloc[:, 1:]\n",
    "    shorelines_df['dates'] = pd.to_datetime(shorelines_df['dates'])\n",
    "    shorelines_df.set_index('dates', inplace=True)\n",
    "    shorelines_df['years'] = shorelines_df.index.year\n",
    "    shorelines_df['months'] = shorelines_df.index.month\n",
    "    shorelines_df.index = pd.MultiIndex.from_tuples(\n",
    "    [(year, month) for year, month in zip(shorelines_df.index.year, shorelines_df.index.month)],\n",
    "    names=['years', 'months'])\n",
    "\n",
    "   \n",
    "    # Read the transects GeoJSON file into a GeoDataFrame\n",
    "    transects_gdf = gpd.read_file(transects_file_path, driver='GeoJSON')\n",
    "\n",
    "    # Add DataFrames to the dictionary with site name as key\n",
    "    data[name] = {\n",
    "        'waves': waves_df,\n",
    "        'shorelines': shorelines_df,\n",
    "        'transects': transects_gdf\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6af609b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty dictionary to store the results\n",
    "annual_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f54b6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over keys in the data dictionary\n",
    "for name in data.keys():\n",
    "    waves_df = data[name]['waves']\n",
    "\n",
    "    waves_df = waves_df.drop(['years', 'months'], axis=1)\n",
    "    \n",
    "    waves_df_annual = waves_df.groupby([waves_df.index.get_level_values('years'), waves_df.index.get_level_values('months')]).agg(\n",
    "           {\n",
    "        f'{name}_pp1d_from_N'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_N'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_NNE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_NNE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_NE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_NE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_ENE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_ENE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_E'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_E'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_ESE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_ESE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_SE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_SE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_SSE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_SSE'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_S'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_S'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_SSW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_SSW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_SW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_SW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_WSW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_WSW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_W'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_W'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_WNW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_WNW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_NW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_NW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_pp1d_from_NNW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None,\n",
    "        f'{name}_swh_from_NNW'  : lambda x: x[x != 0].quantile(0.5) if any(x != 0) else None\n",
    "        })\n",
    "\n",
    "    waves_df_annual = waves_df_annual.fillna(0)\n",
    "    \n",
    "    shoreline_df = data[name]['shorelines']\n",
    "\n",
    "    # Create a MultiIndex with all possible combinations of years and months\n",
    "    all_years = shoreline_df.index.get_level_values('years').unique()\n",
    "    all_months = range(1, 13)\n",
    "    all_combinations = [(year, month) for year in all_years for month in all_months]\n",
    "\n",
    "    full_index = pd.MultiIndex.from_tuples(all_combinations, names=['years', 'months'])\n",
    "\n",
    "    # Group by the MultiIndex and calculate the median\n",
    "    shoreline_df_annual = shoreline_df.groupby(level=['years', 'months']).median(numeric_only=True)\n",
    "\n",
    "    # Reindex with the full MultiIndex to fill missing combinations with NaN\n",
    "    shoreline_df_annual = shoreline_df_annual.reindex(full_index)\n",
    "    \n",
    "    # Drop year and month columns\n",
    "    shoreline_df_annual = shoreline_df_annual.drop(['years', 'months'], axis=1)\n",
    "\n",
    "    # Iterate over each column in the DataFrame\n",
    "\n",
    "    for i in range(1, len(shoreline_df_annual.columns) - 1):\n",
    "        col = shoreline_df_annual.columns[i]\n",
    "    \n",
    "        # Skip columns with names \"years\" or \"months\"\n",
    "        if col.lower() not in ['years', 'months']:\n",
    "            prev_col = shoreline_df_annual.columns[i - 1] if i - 1 >= 0 else None\n",
    "            next_col = shoreline_df_annual.columns[i + 1] if i + 1 < len(shoreline_df_annual.columns) else None\n",
    "\n",
    "            # Check if there are any NaN values in the current column\n",
    "            if shoreline_df_annual[col].isnull().any():\n",
    "                # Fill NaN values with the mean of the available previous and next columns\n",
    "                if prev_col is not None and next_col is not None:\n",
    "                    shoreline_df_annual[col] = (shoreline_df_annual[prev_col] + shoreline_df_annual[next_col]) / 2\n",
    "                elif prev_col is not None:\n",
    "                    shoreline_df_annual[col] = shoreline_df_annual[prev_col]\n",
    "                elif next_col is not None:\n",
    "                    shoreline_df_annual[col] = shoreline_df_annual[next_col]\n",
    "                else:\n",
    "                    # If there are no immediate previous and next columns, extend the search to 3 columns\n",
    "                    prev_cols = [shoreline_df_annual.columns[j] for j in range(i - 2, i) if j >= 0]\n",
    "                    next_cols = [shoreline_df_annual.columns[j] for j in range(i + 1, i + 4) if j < len(shoreline_df_annual.columns)]\n",
    "\n",
    "                    available_cols = prev_cols + next_cols\n",
    "\n",
    "                    # Filter out None values (columns that are out of range)\n",
    "                    available_cols = [col for col in available_cols if col is not None]\n",
    "\n",
    "                    # Take the mean of available columns\n",
    "                    if len(available_cols) > 0:\n",
    "                        shoreline_df_annual[col] = shoreline_df_annual[available_cols].mean(axis=1)\n",
    "\n",
    "    # Perform median replacement only for columns that are not \"years\" or \"months\"\n",
    "    for column in shoreline_df_annual.columns:\n",
    "        if column.lower() not in ['years', 'months']:\n",
    "            # Check if there are any NaN values in the column\n",
    "            if shoreline_df_annual[column].isnull().any():\n",
    "                # Calculate the median value of the column (excluding NaN values)\n",
    "                median_value = shoreline_df_annual[column].median()\n",
    "        \n",
    "                # Replace NaN values with the calculated median value\n",
    "                shoreline_df_annual[column].fillna(median_value, inplace=True)\n",
    "        \n",
    "    # Exclude 'years' and 'months' columns for row-wise median calculation\n",
    "    columns_to_consider = [col for col in shoreline_df_annual.columns if col.lower() not in ['years', 'months']]\n",
    "\n",
    "    # Calculate the median for each row, excluding NaNs, across the specified columns\n",
    "    row_median = shoreline_df_annual[columns_to_consider].median(axis=1)\n",
    "\n",
    "    # Use apply along with lambda to replace NaN values in each row with the row's median\n",
    "    shoreline_df_annual[columns_to_consider] = shoreline_df_annual[columns_to_consider].apply(\n",
    "        lambda x: x.fillna(row_median[x.name]), axis=1)    \n",
    "              \n",
    "    # Ensure no NaNs are left before model training\n",
    "    if shoreline_df_annual.isna().any().any():\n",
    "        print(f\"NaNs remain in shorelines data for {name}\")\n",
    "        continue  # Skip this iteration if NaNs are still present\n",
    "            \n",
    "                \n",
    "    # Add the DataFrame to the dictionary with site name as key\n",
    "    annual_data[name] = {\n",
    "        'waves': waves_df_annual,\n",
    "        'shorelines': shoreline_df_annual\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b4c91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "annual_data['TORR']['shorelines']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4e7230",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e4549ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all wave dataframes\n",
    "waves_dfs = []\n",
    "\n",
    "# Loop through each beach's data\n",
    "for name in annual_data:\n",
    "    # Copy the wave DataFrame\n",
    "    df = annual_data[name]['waves'].copy()\n",
    "\n",
    "    # Reset index to turn MultiIndex into columns\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Rename columns to remove the beach prefix\n",
    "    new_columns = {col: col.replace(f'{name}_', '') for col in df.columns}\n",
    "    df.rename(columns=new_columns, inplace=True)\n",
    "\n",
    "    # Add a column for the beach name\n",
    "    df['beach'] = name\n",
    "\n",
    "    # Reorder columns\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]  # move 'beach' to the front\n",
    "    df = df[cols]\n",
    "\n",
    "    # Append to the list\n",
    "    waves_dfs.append(df)\n",
    "\n",
    "# Combine all dataframes into one\n",
    "waves_combined = pd.concat(waves_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1a33ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "waves_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d5fd803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of all shoreline dataframes\n",
    "shorelines_dfs = []\n",
    "\n",
    "# Loop through each beach's data\n",
    "for name in annual_data:\n",
    "    # Copy the shoreline DataFrame\n",
    "    df = annual_data[name]['shorelines'].copy()\n",
    "\n",
    "    # Reset index to turn MultiIndex into columns\n",
    "    df = df.reset_index()\n",
    "\n",
    "    # Rename columns to use generic names\n",
    "    new_columns = {col: f'{col.split(\"_\")[-1]}' for col in df.columns}\n",
    "    df.rename(columns=new_columns, inplace=True)\n",
    "\n",
    "    # Add a column for the beach name\n",
    "    df['beach'] = name\n",
    "\n",
    "    # Reorder columns\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]  # move 'beach' to the front\n",
    "    df = df[cols]\n",
    "\n",
    "    # Append to the list\n",
    "    shorelines_dfs.append(df)\n",
    "\n",
    "# Combine all dataframes into one\n",
    "shorelines_combined = pd.concat(shorelines_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1471497",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "torr_shorelines = shorelines_combined[shorelines_combined['beach'] == 'TORR']\n",
    "torr_shorelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5008e369",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values in the waves_combined table.\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any NaN values in waves_combined\n",
    "waves_nans = waves_combined.isna().any().any()\n",
    "\n",
    "if waves_nans:\n",
    "    print(\"There are NaN values in the waves_combined table.\")\n",
    "else:\n",
    "    print(\"No NaN values in the waves_combined table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e022885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No NaN values in the shorelines_combined table.\n"
     ]
    }
   ],
   "source": [
    "# Check if there are any NaN values in shorelines_combined\n",
    "shorelines_nans = shorelines_combined.isna().any().any()\n",
    "\n",
    "if shorelines_nans:\n",
    "    print(\"There are NaN values in the shorelines_combined table.\")\n",
    "else:\n",
    "    print(\"No NaN values in the shorelines_combined table.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9977e976",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beach</th>\n",
       "      <th>years</th>\n",
       "      <th>months</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ADLA</td>\n",
       "      <td>1984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ADLA</td>\n",
       "      <td>1984</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADLA</td>\n",
       "      <td>1984</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ADLA</td>\n",
       "      <td>1984</td>\n",
       "      <td>4</td>\n",
       "      <td>18.235956</td>\n",
       "      <td>20.693159</td>\n",
       "      <td>18.540051</td>\n",
       "      <td>15.133533</td>\n",
       "      <td>14.589777</td>\n",
       "      <td>14.466450</td>\n",
       "      <td>13.992007</td>\n",
       "      <td>16.393314</td>\n",
       "      <td>11.129181</td>\n",
       "      <td>5.573088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADLA</td>\n",
       "      <td>1984</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>VAGR</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>10.804137</td>\n",
       "      <td>16.260811</td>\n",
       "      <td>-0.163789</td>\n",
       "      <td>-0.930297</td>\n",
       "      <td>10.643900</td>\n",
       "      <td>1.324937</td>\n",
       "      <td>0.999446</td>\n",
       "      <td>13.133079</td>\n",
       "      <td>5.687721</td>\n",
       "      <td>-2.328197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>VAGR</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1.041706</td>\n",
       "      <td>19.780664</td>\n",
       "      <td>-0.959917</td>\n",
       "      <td>-3.462635</td>\n",
       "      <td>9.349269</td>\n",
       "      <td>4.430923</td>\n",
       "      <td>2.758224</td>\n",
       "      <td>6.350465</td>\n",
       "      <td>-3.245225</td>\n",
       "      <td>-13.411474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>VAGR</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>4.119814</td>\n",
       "      <td>23.835732</td>\n",
       "      <td>7.196150</td>\n",
       "      <td>1.242256</td>\n",
       "      <td>12.357720</td>\n",
       "      <td>12.165696</td>\n",
       "      <td>7.851352</td>\n",
       "      <td>20.625551</td>\n",
       "      <td>16.372356</td>\n",
       "      <td>11.548602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>VAGR</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>-11.645939</td>\n",
       "      <td>-5.928786</td>\n",
       "      <td>-15.845567</td>\n",
       "      <td>-22.010816</td>\n",
       "      <td>-4.342059</td>\n",
       "      <td>-9.861837</td>\n",
       "      <td>-12.485654</td>\n",
       "      <td>-14.475632</td>\n",
       "      <td>-18.131533</td>\n",
       "      <td>-22.357994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>VAGR</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>-24.327678</td>\n",
       "      <td>-21.843960</td>\n",
       "      <td>-24.169331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-21.116189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9360 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     beach  years  months          1          2          3          4  \\\n",
       "0     ADLA   1984       1   0.000000   0.000000   0.000000   0.000000   \n",
       "1     ADLA   1984       2   0.000000   0.000000   0.000000   0.000000   \n",
       "2     ADLA   1984       3   0.000000   0.000000   0.000000   0.000000   \n",
       "3     ADLA   1984       4  18.235956  20.693159  18.540051  15.133533   \n",
       "4     ADLA   1984       5   0.000000   0.000000   0.000000   0.000000   \n",
       "...    ...    ...     ...        ...        ...        ...        ...   \n",
       "9355  VAGR   2022       8  10.804137  16.260811  -0.163789  -0.930297   \n",
       "9356  VAGR   2022       9   1.041706  19.780664  -0.959917  -3.462635   \n",
       "9357  VAGR   2022      10   4.119814  23.835732   7.196150   1.242256   \n",
       "9358  VAGR   2022      11 -11.645939  -5.928786 -15.845567 -22.010816   \n",
       "9359  VAGR   2022      12 -24.327678 -21.843960 -24.169331   0.000000   \n",
       "\n",
       "              5          6          7          8          9         10  \n",
       "0      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000  \n",
       "1      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000  \n",
       "2      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000  \n",
       "3     14.589777  14.466450  13.992007  16.393314  11.129181   5.573088  \n",
       "4      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000  \n",
       "...         ...        ...        ...        ...        ...        ...  \n",
       "9355  10.643900   1.324937   0.999446  13.133079   5.687721  -2.328197  \n",
       "9356   9.349269   4.430923   2.758224   6.350465  -3.245225 -13.411474  \n",
       "9357  12.357720  12.165696   7.851352  20.625551  16.372356  11.548602  \n",
       "9358  -4.342059  -9.861837 -12.485654 -14.475632 -18.131533 -22.357994  \n",
       "9359   0.000000   0.000000   0.000000   0.000000   0.000000 -21.116189  \n",
       "\n",
       "[9360 rows x 13 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a function to normalize columns by subtracting the value of month 1, year 1984\n",
    "def normalize_by_reference(df):\n",
    "    # Find the reference row (month 1, year 1984) for the current beach\n",
    "    reference_row = df[(df['years'] == 1984) & (df['months'] == 1)]\n",
    "\n",
    "\n",
    "    # Otherwise, subtract the reference value from all rows in the dataframe\n",
    "    for col in df.columns:\n",
    "        if col not in ['years', 'months', 'beach']:\n",
    "            df[col] -= reference_row[col].values[0]\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the normalization function to each beach group\n",
    "shorelines_normalized = shorelines_combined.groupby('beach', group_keys=True).apply(normalize_by_reference).reset_index(drop=True)\n",
    "shorelines_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff90985",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torr_shorelines_normalized = shorelines_normalized[shorelines_normalized['beach'] == 'TORR']\n",
    "torr_shorelines_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ae9c501",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beach</th>\n",
       "      <th>years</th>\n",
       "      <th>months</th>\n",
       "      <th>pp1d_from_N</th>\n",
       "      <th>swh_from_N</th>\n",
       "      <th>pp1d_from_NNE</th>\n",
       "      <th>swh_from_NNE</th>\n",
       "      <th>pp1d_from_NE</th>\n",
       "      <th>swh_from_NE</th>\n",
       "      <th>pp1d_from_ENE</th>\n",
       "      <th>...</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CVCC</td>\n",
       "      <td>1984</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CVCC</td>\n",
       "      <td>1984</td>\n",
       "      <td>2</td>\n",
       "      <td>8.124553</td>\n",
       "      <td>0.898709</td>\n",
       "      <td>10.150081</td>\n",
       "      <td>0.979162</td>\n",
       "      <td>4.325909</td>\n",
       "      <td>0.938027</td>\n",
       "      <td>12.076363</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CVCC</td>\n",
       "      <td>1984</td>\n",
       "      <td>3</td>\n",
       "      <td>11.416148</td>\n",
       "      <td>1.212591</td>\n",
       "      <td>10.845699</td>\n",
       "      <td>1.179881</td>\n",
       "      <td>9.994397</td>\n",
       "      <td>1.151467</td>\n",
       "      <td>10.096162</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CVCC</td>\n",
       "      <td>1984</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-117.597740</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CVCC</td>\n",
       "      <td>1984</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>MIRA</td>\n",
       "      <td>2022</td>\n",
       "      <td>8</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.684163</td>\n",
       "      <td>6.985749</td>\n",
       "      <td>8.469560</td>\n",
       "      <td>2.602996</td>\n",
       "      <td>14.479233</td>\n",
       "      <td>-2.095405</td>\n",
       "      <td>-34.434764</td>\n",
       "      <td>-44.139283</td>\n",
       "      <td>-28.326693</td>\n",
       "      <td>-16.634225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>MIRA</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-14.976500</td>\n",
       "      <td>-4.118891</td>\n",
       "      <td>1.947118</td>\n",
       "      <td>2.640465</td>\n",
       "      <td>5.385459</td>\n",
       "      <td>-16.721884</td>\n",
       "      <td>-40.496321</td>\n",
       "      <td>-53.866435</td>\n",
       "      <td>-40.018042</td>\n",
       "      <td>-30.289771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>MIRA</td>\n",
       "      <td>2022</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.311467</td>\n",
       "      <td>16.138400</td>\n",
       "      <td>17.186364</td>\n",
       "      <td>10.319524</td>\n",
       "      <td>15.116868</td>\n",
       "      <td>6.445768</td>\n",
       "      <td>-30.248808</td>\n",
       "      <td>-36.877415</td>\n",
       "      <td>-27.219336</td>\n",
       "      <td>-21.681380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>MIRA</td>\n",
       "      <td>2022</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-39.317704</td>\n",
       "      <td>-27.213373</td>\n",
       "      <td>-24.844876</td>\n",
       "      <td>-20.613260</td>\n",
       "      <td>-13.874573</td>\n",
       "      <td>-28.102132</td>\n",
       "      <td>-51.060485</td>\n",
       "      <td>-65.600963</td>\n",
       "      <td>-55.998810</td>\n",
       "      <td>-50.516779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>MIRA</td>\n",
       "      <td>2022</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-41.550498</td>\n",
       "      <td>-23.804524</td>\n",
       "      <td>-25.186046</td>\n",
       "      <td>-12.488719</td>\n",
       "      <td>-16.258711</td>\n",
       "      <td>-29.652593</td>\n",
       "      <td>-52.049105</td>\n",
       "      <td>-60.844939</td>\n",
       "      <td>-49.481906</td>\n",
       "      <td>-42.238996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9360 rows × 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     beach  years  months  pp1d_from_N  swh_from_N  pp1d_from_NNE  \\\n",
       "0     CVCC   1984       1     0.000000    0.000000       0.000000   \n",
       "1     CVCC   1984       2     8.124553    0.898709      10.150081   \n",
       "2     CVCC   1984       3    11.416148    1.212591      10.845699   \n",
       "3     CVCC   1984       4     0.000000    0.000000       0.000000   \n",
       "4     CVCC   1984       5     0.000000    0.000000       0.000000   \n",
       "...    ...    ...     ...          ...         ...            ...   \n",
       "9355  MIRA   2022       8     0.000000    0.000000       0.000000   \n",
       "9356  MIRA   2022       9     0.000000    0.000000       0.000000   \n",
       "9357  MIRA   2022      10     0.000000    0.000000       0.000000   \n",
       "9358  MIRA   2022      11     0.000000    0.000000       0.000000   \n",
       "9359  MIRA   2022      12     0.000000    0.000000       0.000000   \n",
       "\n",
       "      swh_from_NNE  pp1d_from_NE  swh_from_NE  pp1d_from_ENE  ...           1  \\\n",
       "0         0.000000      0.000000     0.000000       0.000000  ...    0.000000   \n",
       "1         0.979162      4.325909     0.938027      12.076363  ...    0.000000   \n",
       "2         1.179881      9.994397     1.151467      10.096162  ...    0.000000   \n",
       "3         0.000000      0.000000     0.000000       0.000000  ... -117.597740   \n",
       "4         0.000000      0.000000     0.000000       0.000000  ...    0.000000   \n",
       "...            ...           ...          ...            ...  ...         ...   \n",
       "9355      0.000000      0.000000     0.000000       0.000000  ...    7.684163   \n",
       "9356      0.000000      0.000000     0.000000       0.000000  ...  -14.976500   \n",
       "9357      0.000000      0.000000     0.000000       0.000000  ...    8.311467   \n",
       "9358      0.000000      0.000000     0.000000       0.000000  ...  -39.317704   \n",
       "9359      0.000000      0.000000     0.000000       0.000000  ...  -41.550498   \n",
       "\n",
       "              2          3          4          5          6          7  \\\n",
       "0      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "1      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "2      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "3      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "4      0.000000   0.000000   0.000000   0.000000   0.000000   0.000000   \n",
       "...         ...        ...        ...        ...        ...        ...   \n",
       "9355   6.985749   8.469560   2.602996  14.479233  -2.095405 -34.434764   \n",
       "9356  -4.118891   1.947118   2.640465   5.385459 -16.721884 -40.496321   \n",
       "9357  16.138400  17.186364  10.319524  15.116868   6.445768 -30.248808   \n",
       "9358 -27.213373 -24.844876 -20.613260 -13.874573 -28.102132 -51.060485   \n",
       "9359 -23.804524 -25.186046 -12.488719 -16.258711 -29.652593 -52.049105   \n",
       "\n",
       "              8          9         10  \n",
       "0      0.000000   0.000000   0.000000  \n",
       "1      0.000000   0.000000   0.000000  \n",
       "2      0.000000   0.000000   0.000000  \n",
       "3      0.000000   0.000000   0.000000  \n",
       "4      0.000000   0.000000   0.000000  \n",
       "...         ...        ...        ...  \n",
       "9355 -44.139283 -28.326693 -16.634225  \n",
       "9356 -53.866435 -40.018042 -30.289771  \n",
       "9357 -36.877415 -27.219336 -21.681380  \n",
       "9358 -65.600963 -55.998810 -50.516779  \n",
       "9359 -60.844939 -49.481906 -42.238996  \n",
       "\n",
       "[9360 rows x 45 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the waves_combined and shorelines_normalized dataframes\n",
    "# This will join the tables on 'years', 'months', and 'beach'\n",
    "combined_data = pd.merge(waves_combined, shorelines_normalized, how='inner', on=['years', 'months', 'beach'])\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "87705981",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anapa\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# One-hot encode the 'beach' column\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "beach_encoded = encoder.fit_transform(combined_data[['beach']])\n",
    "\n",
    "# Create a DataFrame from the encoded array\n",
    "beach_encoded_df = pd.DataFrame(beach_encoded, columns=encoder.get_feature_names_out(['beach']), index=combined_data.index)\n",
    "\n",
    "# Drop the original 'beach' column from combined_data\n",
    "combined_data = combined_data.drop('beach', axis=1)\n",
    "\n",
    "# Concatenate the one-hot encoded beach column with combined_data\n",
    "combined_data = pd.concat([combined_data, beach_encoded_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "64f91bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the combined data into training and testing sets\n",
    "\n",
    "# Filter rows for training data (years <= 2014)\n",
    "training_data = combined_data[combined_data['years'] <= 2014]\n",
    "\n",
    "# Filter rows for testing data (years > 2014)\n",
    "testing_data = combined_data[combined_data['years'] > 2014]\n",
    "\n",
    "# Define the columns for the target variables\n",
    "target_columns = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "\n",
    "# For training set\n",
    "x_train = training_data.drop(target_columns + ['years', 'months'], axis=1)\n",
    "y_train = training_data[target_columns]\n",
    "\n",
    "# For testing set\n",
    "x_test = testing_data.drop(target_columns + ['years', 'months'], axis=1)\n",
    "y_test = testing_data[target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "44b30d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pp1d_from_N</th>\n",
       "      <th>swh_from_N</th>\n",
       "      <th>pp1d_from_NNE</th>\n",
       "      <th>swh_from_NNE</th>\n",
       "      <th>pp1d_from_NE</th>\n",
       "      <th>swh_from_NE</th>\n",
       "      <th>pp1d_from_ENE</th>\n",
       "      <th>swh_from_ENE</th>\n",
       "      <th>pp1d_from_E</th>\n",
       "      <th>swh_from_E</th>\n",
       "      <th>...</th>\n",
       "      <th>beach_LABI</th>\n",
       "      <th>beach_MCCO</th>\n",
       "      <th>beach_MEIA</th>\n",
       "      <th>beach_MGVR</th>\n",
       "      <th>beach_MIRA</th>\n",
       "      <th>beach_MRMG</th>\n",
       "      <th>beach_NNOR</th>\n",
       "      <th>beach_TORR</th>\n",
       "      <th>beach_TRAT</th>\n",
       "      <th>beach_VAGR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>11.011012</td>\n",
       "      <td>1.164683</td>\n",
       "      <td>11.073523</td>\n",
       "      <td>1.369202</td>\n",
       "      <td>10.976942</td>\n",
       "      <td>1.059284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.958426</td>\n",
       "      <td>1.115618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pp1d_from_N  swh_from_N  pp1d_from_NNE  swh_from_NNE  pp1d_from_NE  \\\n",
       "372      0.000000    0.000000       0.000000      0.000000      0.000000   \n",
       "373     11.011012    1.164683      11.073523      1.369202     10.976942   \n",
       "374      0.000000    0.000000       0.000000      0.000000      0.000000   \n",
       "375      0.000000    0.000000       0.000000      0.000000      0.000000   \n",
       "376      0.000000    0.000000       0.000000      0.000000      0.000000   \n",
       "...           ...         ...            ...           ...           ...   \n",
       "9355     0.000000    0.000000       0.000000      0.000000      0.000000   \n",
       "9356     0.000000    0.000000       0.000000      0.000000      0.000000   \n",
       "9357     0.000000    0.000000       0.000000      0.000000      0.000000   \n",
       "9358     0.000000    0.000000       0.000000      0.000000      0.000000   \n",
       "9359     0.000000    0.000000       0.000000      0.000000      0.000000   \n",
       "\n",
       "      swh_from_NE  pp1d_from_ENE  swh_from_ENE  pp1d_from_E  swh_from_E  ...  \\\n",
       "372      0.000000            0.0           0.0     0.000000    0.000000  ...   \n",
       "373      1.059284            0.0           0.0    10.958426    1.115618  ...   \n",
       "374      0.000000            0.0           0.0     0.000000    0.000000  ...   \n",
       "375      0.000000            0.0           0.0     0.000000    0.000000  ...   \n",
       "376      0.000000            0.0           0.0     0.000000    0.000000  ...   \n",
       "...           ...            ...           ...          ...         ...  ...   \n",
       "9355     0.000000            0.0           0.0     0.000000    0.000000  ...   \n",
       "9356     0.000000            0.0           0.0     0.000000    0.000000  ...   \n",
       "9357     0.000000            0.0           0.0     0.000000    0.000000  ...   \n",
       "9358     0.000000            0.0           0.0     0.000000    0.000000  ...   \n",
       "9359     0.000000            0.0           0.0     0.000000    0.000000  ...   \n",
       "\n",
       "      beach_LABI  beach_MCCO  beach_MEIA  beach_MGVR  beach_MIRA  beach_MRMG  \\\n",
       "372          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "373          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "374          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "375          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "376          0.0         0.0         0.0         0.0         0.0         0.0   \n",
       "...          ...         ...         ...         ...         ...         ...   \n",
       "9355         0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "9356         0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "9357         0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "9358         0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "9359         0.0         0.0         0.0         0.0         1.0         0.0   \n",
       "\n",
       "      beach_NNOR  beach_TORR  beach_TRAT  beach_VAGR  \n",
       "372          0.0         0.0         0.0         0.0  \n",
       "373          0.0         0.0         0.0         0.0  \n",
       "374          0.0         0.0         0.0         0.0  \n",
       "375          0.0         0.0         0.0         0.0  \n",
       "376          0.0         0.0         0.0         0.0  \n",
       "...          ...         ...         ...         ...  \n",
       "9355         0.0         0.0         0.0         0.0  \n",
       "9356         0.0         0.0         0.0         0.0  \n",
       "9357         0.0         0.0         0.0         0.0  \n",
       "9358         0.0         0.0         0.0         0.0  \n",
       "9359         0.0         0.0         0.0         0.0  \n",
       "\n",
       "[1920 rows x 52 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8160fd8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beach</th>\n",
       "      <th>pp1d_from_N</th>\n",
       "      <th>swh_from_N</th>\n",
       "      <th>pp1d_from_NNE</th>\n",
       "      <th>swh_from_NNE</th>\n",
       "      <th>pp1d_from_NE</th>\n",
       "      <th>swh_from_NE</th>\n",
       "      <th>pp1d_from_ENE</th>\n",
       "      <th>swh_from_ENE</th>\n",
       "      <th>pp1d_from_E</th>\n",
       "      <th>...</th>\n",
       "      <th>pp1d_from_WSW</th>\n",
       "      <th>swh_from_WSW</th>\n",
       "      <th>pp1d_from_W</th>\n",
       "      <th>swh_from_W</th>\n",
       "      <th>pp1d_from_WNW</th>\n",
       "      <th>swh_from_WNW</th>\n",
       "      <th>pp1d_from_NW</th>\n",
       "      <th>swh_from_NW</th>\n",
       "      <th>pp1d_from_NNW</th>\n",
       "      <th>swh_from_NNW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>CVCC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.491076</td>\n",
       "      <td>1.198384</td>\n",
       "      <td>13.541367</td>\n",
       "      <td>1.905114</td>\n",
       "      <td>14.648787</td>\n",
       "      <td>2.826441</td>\n",
       "      <td>11.905569</td>\n",
       "      <td>2.097821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>CVCC</td>\n",
       "      <td>11.011012</td>\n",
       "      <td>1.164683</td>\n",
       "      <td>11.073523</td>\n",
       "      <td>1.369202</td>\n",
       "      <td>10.976942</td>\n",
       "      <td>1.059284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.958426</td>\n",
       "      <td>...</td>\n",
       "      <td>13.551736</td>\n",
       "      <td>0.804875</td>\n",
       "      <td>13.325838</td>\n",
       "      <td>0.783068</td>\n",
       "      <td>13.400940</td>\n",
       "      <td>2.766638</td>\n",
       "      <td>12.943959</td>\n",
       "      <td>2.771264</td>\n",
       "      <td>10.992348</td>\n",
       "      <td>2.137387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>CVCC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.071030</td>\n",
       "      <td>2.317126</td>\n",
       "      <td>13.691127</td>\n",
       "      <td>2.108807</td>\n",
       "      <td>13.690386</td>\n",
       "      <td>2.240968</td>\n",
       "      <td>10.917246</td>\n",
       "      <td>2.451765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>CVCC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.887028</td>\n",
       "      <td>2.006135</td>\n",
       "      <td>11.129812</td>\n",
       "      <td>1.725045</td>\n",
       "      <td>12.616592</td>\n",
       "      <td>1.559513</td>\n",
       "      <td>11.381337</td>\n",
       "      <td>1.471296</td>\n",
       "      <td>12.660587</td>\n",
       "      <td>2.522553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>CVCC</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9.955587</td>\n",
       "      <td>3.200043</td>\n",
       "      <td>10.760673</td>\n",
       "      <td>1.901975</td>\n",
       "      <td>10.024467</td>\n",
       "      <td>1.501032</td>\n",
       "      <td>11.145662</td>\n",
       "      <td>1.728762</td>\n",
       "      <td>8.764474</td>\n",
       "      <td>1.700430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9355</th>\n",
       "      <td>MIRA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.188249</td>\n",
       "      <td>0.664454</td>\n",
       "      <td>8.457845</td>\n",
       "      <td>1.108349</td>\n",
       "      <td>8.790249</td>\n",
       "      <td>1.480382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9356</th>\n",
       "      <td>MIRA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>12.173240</td>\n",
       "      <td>2.308535</td>\n",
       "      <td>9.700359</td>\n",
       "      <td>1.217052</td>\n",
       "      <td>10.688978</td>\n",
       "      <td>1.292548</td>\n",
       "      <td>10.430787</td>\n",
       "      <td>1.813675</td>\n",
       "      <td>8.112554</td>\n",
       "      <td>2.067011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9357</th>\n",
       "      <td>MIRA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.234812</td>\n",
       "      <td>2.558815</td>\n",
       "      <td>11.438960</td>\n",
       "      <td>2.600941</td>\n",
       "      <td>10.592397</td>\n",
       "      <td>1.730166</td>\n",
       "      <td>11.204914</td>\n",
       "      <td>1.609404</td>\n",
       "      <td>11.528874</td>\n",
       "      <td>1.703321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9358</th>\n",
       "      <td>MIRA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.634862</td>\n",
       "      <td>2.579548</td>\n",
       "      <td>12.441947</td>\n",
       "      <td>2.454408</td>\n",
       "      <td>13.128974</td>\n",
       "      <td>3.174024</td>\n",
       "      <td>12.206421</td>\n",
       "      <td>2.616470</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9359</th>\n",
       "      <td>MIRA</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>11.596422</td>\n",
       "      <td>3.058631</td>\n",
       "      <td>11.915345</td>\n",
       "      <td>2.707909</td>\n",
       "      <td>12.154575</td>\n",
       "      <td>2.199007</td>\n",
       "      <td>10.572251</td>\n",
       "      <td>1.755772</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1920 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     beach  pp1d_from_N  swh_from_N  pp1d_from_NNE  swh_from_NNE  \\\n",
       "372   CVCC     0.000000    0.000000       0.000000      0.000000   \n",
       "373   CVCC    11.011012    1.164683      11.073523      1.369202   \n",
       "374   CVCC     0.000000    0.000000       0.000000      0.000000   \n",
       "375   CVCC     0.000000    0.000000       0.000000      0.000000   \n",
       "376   CVCC     0.000000    0.000000       0.000000      0.000000   \n",
       "...    ...          ...         ...            ...           ...   \n",
       "9355  MIRA     0.000000    0.000000       0.000000      0.000000   \n",
       "9356  MIRA     0.000000    0.000000       0.000000      0.000000   \n",
       "9357  MIRA     0.000000    0.000000       0.000000      0.000000   \n",
       "9358  MIRA     0.000000    0.000000       0.000000      0.000000   \n",
       "9359  MIRA     0.000000    0.000000       0.000000      0.000000   \n",
       "\n",
       "      pp1d_from_NE  swh_from_NE  pp1d_from_ENE  swh_from_ENE  pp1d_from_E  \\\n",
       "372       0.000000     0.000000            0.0           0.0     0.000000   \n",
       "373      10.976942     1.059284            0.0           0.0    10.958426   \n",
       "374       0.000000     0.000000            0.0           0.0     0.000000   \n",
       "375       0.000000     0.000000            0.0           0.0     0.000000   \n",
       "376       0.000000     0.000000            0.0           0.0     0.000000   \n",
       "...            ...          ...            ...           ...          ...   \n",
       "9355      0.000000     0.000000            0.0           0.0     0.000000   \n",
       "9356      0.000000     0.000000            0.0           0.0     0.000000   \n",
       "9357      0.000000     0.000000            0.0           0.0     0.000000   \n",
       "9358      0.000000     0.000000            0.0           0.0     0.000000   \n",
       "9359      0.000000     0.000000            0.0           0.0     0.000000   \n",
       "\n",
       "      ...  pp1d_from_WSW  swh_from_WSW  pp1d_from_W  swh_from_W  \\\n",
       "372   ...       0.000000      0.000000    10.491076    1.198384   \n",
       "373   ...      13.551736      0.804875    13.325838    0.783068   \n",
       "374   ...       0.000000      0.000000    12.071030    2.317126   \n",
       "375   ...      10.887028      2.006135    11.129812    1.725045   \n",
       "376   ...       9.955587      3.200043    10.760673    1.901975   \n",
       "...   ...            ...           ...          ...         ...   \n",
       "9355  ...       0.000000      0.000000     0.000000    0.000000   \n",
       "9356  ...      12.173240      2.308535     9.700359    1.217052   \n",
       "9357  ...      10.234812      2.558815    11.438960    2.600941   \n",
       "9358  ...      14.634862      2.579548    12.441947    2.454408   \n",
       "9359  ...      11.596422      3.058631    11.915345    2.707909   \n",
       "\n",
       "      pp1d_from_WNW  swh_from_WNW  pp1d_from_NW  swh_from_NW  pp1d_from_NNW  \\\n",
       "372       13.541367      1.905114     14.648787     2.826441      11.905569   \n",
       "373       13.400940      2.766638     12.943959     2.771264      10.992348   \n",
       "374       13.691127      2.108807     13.690386     2.240968      10.917246   \n",
       "375       12.616592      1.559513     11.381337     1.471296      12.660587   \n",
       "376       10.024467      1.501032     11.145662     1.728762       8.764474   \n",
       "...             ...           ...           ...          ...            ...   \n",
       "9355       8.188249      0.664454      8.457845     1.108349       8.790249   \n",
       "9356      10.688978      1.292548     10.430787     1.813675       8.112554   \n",
       "9357      10.592397      1.730166     11.204914     1.609404      11.528874   \n",
       "9358      13.128974      3.174024     12.206421     2.616470       0.000000   \n",
       "9359      12.154575      2.199007     10.572251     1.755772       0.000000   \n",
       "\n",
       "      swh_from_NNW  \n",
       "372       2.097821  \n",
       "373       2.137387  \n",
       "374       2.451765  \n",
       "375       2.522553  \n",
       "376       1.700430  \n",
       "...            ...  \n",
       "9355      1.480382  \n",
       "9356      2.067011  \n",
       "9357      1.703321  \n",
       "9358      0.000000  \n",
       "9359      0.000000  \n",
       "\n",
       "[1920 rows x 33 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "65264ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the DecisionTreeRegressor model\n",
    "model = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "747fd76c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7a9d2b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred = model.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1d17bf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26.527286898965592"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and print the metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e154a03a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbef7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross validation com time series split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c9853517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline dummy que prevê o ano a seguir com base no anterior (igual)\n",
    "\n",
    "# Splitting the combined data into training and testing sets - Naive model to compare\n",
    "\n",
    "# Train for 2021\n",
    "training_data_naive = combined_data[combined_data['years'] == 2021]\n",
    "\n",
    "# Test for 2022\n",
    "testing_data_naive = combined_data[combined_data['years'] == 2022]\n",
    "\n",
    "# Define the columns for the target variables\n",
    "target_columns = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10']\n",
    "\n",
    "# For training set\n",
    "x_train_naive = training_data_naive.drop(target_columns + ['years', 'months'], axis=1)\n",
    "y_train_naive = training_data_naive[target_columns]\n",
    "\n",
    "# For testing set\n",
    "x_test_naive = testing_data_naive.drop(target_columns + ['years', 'months'], axis=1)\n",
    "y_test_naive = testing_data_naive[target_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "b62a7781",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of the DecisionTreeRegressor model\n",
    "model_naive = DecisionTreeRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "aae21d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeRegressor()"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model_naive.fit(x_train_naive, y_train_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4e43ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the test set\n",
    "y_pred_naive = model_naive.predict(x_test_naive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7f77c8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.8933687600227"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate and print the metrics for the naive model\n",
    "mse_naive = mean_squared_error(y_test_naive, y_pred_naive)\n",
    "rmse_naive = mean_squared_error(y_test_naive, y_pred_naive, squared=False)\n",
    "rmse_naive"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
